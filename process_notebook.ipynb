{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run\n",
    "\n",
    "```sh\n",
    "git clone <this branch>\n",
    "cd diffusers\n",
    "python -m venv ./venv\n",
    "source .venv/bin/activate\n",
    "pip install -U pip wheel\n",
    "pip install -e .[torch]\n",
    "pip install --upgrade transformers scipy\n",
    "pip install jupyterlab moviepy\n",
    "````\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Generator\n",
    "from diffusers import DiffusionPipeline\n",
    "import moviepy.editor as mpy\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "device = torch.device(\"cuda\")\n",
    "pipe = DiffusionPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-2-1\"\n",
    ")\n",
    "pipe.to(device)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ?pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(type(pipe))\n",
    "print(type(pipe.text_encoder))\n",
    "print(type(pipe.unet))\n",
    "print(type(pipe.vae))\n",
    "print(type(pipe.scheduler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generator = torch.Generator(device=device)\n",
    "generator.manual_seed(1)\n",
    "\n",
    "tape = []\n",
    "\n",
    "@torch.no_grad()\n",
    "def callback(i, t, latents):\n",
    "    latents = latents.detach().clone()\n",
    "    instant = (i, t, latents)\n",
    "    tape.append(instant)\n",
    "\n",
    "prompt = [\"A photo of a white robot in tall grass with staring at clouds in the blue sky\"]\n",
    "result = pipe(\n",
    "    prompt=prompt,\n",
    "    num_inference_steps=50,\n",
    "    num_images_per_prompt=3,\n",
    "    callback=callback,\n",
    "    generator=generator,\n",
    "    guidance_scale=7.5,\n",
    ")\n",
    "for image in result.images:\n",
    "    display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_seq = []\n",
    "for (i, t, latents) in tqdm.tqdm(tape):\n",
    "    images = pipe.decode_latents(latents)\n",
    "    images = (images * 255).astype(np.uint8)\n",
    "    image = np.concatenate(images, axis=1)\n",
    "    image_seq.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clip = mpy.ImageSequenceClip(image_seq + 70 * image_seq[-1:], fps=20)\n",
    "clip.write_videofile(\"/tmp/vid.mp4\")\n",
    "# clip.write_gif(\"/tmp/vid.gif\")\n",
    "!gifski /tmp/vid.mp4 --width 1200 -o /tmp/vid.gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
